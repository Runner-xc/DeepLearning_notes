{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrossEntropy Loss | 交叉熵损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 交叉熵\n",
    "\n",
    "在信息学中 **信息熵(entropy)** 是表示系统的混乱程度和确定性的。**交叉熵（Cross Entropy）** 是一种衡量两个概率分布之间的相似程度的指标。\n",
    "在机器学习中，交叉熵常常用于评估模型预测结果与真实标签之间的差距。交叉熵越小，说明模型预测结果与真实标签越接近，模型性能越好。\n",
    "\n",
    "交叉熵的公式如下：\n",
    "$$\n",
    "H(p,q) = -\\sum_{i=1}^{n} p(x_i) \\log q(x_i)\n",
    "$$\n",
    "\n",
    "其中:\n",
    "- $p$ 是真实分布\n",
    "- $x_i$ 是预测样本\n",
    "- $q$ 是预测分布\n",
    "- $n$ 是类别数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. 二分类交叉熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 二分类问题 ，其交叉熵损失计算为：\n",
    "$$\n",
    "CE_{loss}(p,y) =\n",
    "\\begin{cases}\n",
    "     -\\log(p), & \\text{if } y = 1 \\\\\n",
    "    -\\log(1-p), & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "或者是：\n",
    "$$CE_{loss} = -[y \\cdot log(p) + (1-y) \\cdot log(1-p)]$$\n",
    "\n",
    "其中:\n",
    "- $p$ 是预测为正例（y=1）的概率\n",
    "- $y$ 是真实标签（0 或 1）\n",
    "\n",
    "$p$与$y$的关系为：\n",
    "\n",
    "$$\n",
    "p_t = \n",
    "\\begin{cases}\n",
    "     p, & \\text{if } y = 1 \\\\\n",
    "    1-p, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "因此交叉熵也可表示为：\n",
    "$$CE_{loss}(p, y) = CE_{loss}(p_t) = - \\log (p_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 多分类交叉熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多分类交叉熵公式如下：<br>\n",
    "$$\n",
    "\n",
    "CE_{loss} = - \\sum_{i}^{C} [y_i \\cdot log(p_i) + (1-y_i) \\cdot log(1-p_i)]\n",
    "$$\n",
    "\n",
    "<!-- 如果看作只计算预测正确的概率的交叉熵，那么公式可以简化为：<br>\n",
    "$$\n",
    "CE_{loss} = - \\sum_{i}^{C} log(p_i)\n",
    "$$ -->\n",
    "- $C$ 是类别数\n",
    "- $y_i$ 是第 $i$ 类的标签，如果第 $i$ 类是正样本，那么 $y_i=1$，否则 $y_i=0$\n",
    "- $p_i$ 是第 $i$ 类的预测正确的概率\n",
    "$ 0 < p_i < 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 代码实现\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 二分类交叉熵实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([[0.8000, 0.2000],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.7000, 0.3000]])\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义输出和标签\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_tensor = torch.tensor([[0.8, 0.2],  # 样本概率\n",
    "                             [0.3, 0.7], \n",
    "                             [0.7, 0.3]]\n",
    "                             ).float()\n",
    "\n",
    "label_tensor = torch.tensor([0, 1, 0]) # C =2\n",
    "# label_tensor = label_tensor.view(-1) # 规定label_tensor的最后维度为类别维度\n",
    "print(label_tensor.shape)\n",
    "label_tensor = F.one_hot(label_tensor, num_classes=2).float()\n",
    "\n",
    "print(input_tensor)\n",
    "print(label_tensor)\n",
    "\n",
    "input_tensor.shape, label_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4878)\n"
     ]
    }
   ],
   "source": [
    "# 定义自定义的交叉熵损失函数\n",
    "\n",
    "class CustomCELoss(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(CustomCELoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, label_tensor):\n",
    "        prob_logs = torch.log_softmax(input_tensor, dim=1)\n",
    "        loss = -torch.sum(label_tensor * prob_logs, dim=1)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(loss)\n",
    "        else:\n",
    "            return loss\n",
    "    \n",
    "custom_loss_fn = CustomCELoss(reduction='mean')\n",
    "custom_loss = custom_loss_fn(input_tensor, label_tensor)\n",
    "print(custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4878)\n"
     ]
    }
   ],
   "source": [
    "# 与官方的交叉熵损失函数比较\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "official_loss_fn = CrossEntropyLoss(reduction='mean')\n",
    "official_loss = official_loss_fn(input_tensor, label_tensor)\n",
    "print(official_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 多分类交叉熵实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 128, 128, 128]) torch.Size([1, 4, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# 随机生成多维的输入（预测probs）和标签\n",
    "\n",
    "import torch\n",
    "\n",
    "input_tensor = torch.rand(1, 4, 128, 128, 128).float()\n",
    "label_tensor = torch.randint(0, 4, (1, 128, 128, 128))\n",
    "label_tensor = F.one_hot(label_tensor, num_classes=4).permute(0, 4, 1, 2, 3).float()\n",
    "\n",
    "print(input_tensor.shape, label_tensor.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4174)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_loss_fn(input_tensor, label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4174)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_loss_fn(input_tensor, label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
